version: '3.9'

services:
  convert-modelfile-to-gguf:
    container_name: convert-modelfile-to-gguf
    hostname: convert-modelfile-to-gguf
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    build:
      context: .
      dockerfile: Dockerfile
      args:
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        FTP_PROXY: ${FTP_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
        http_proxy: ${HTTP_PROXY:-}
        https_proxy: ${HTTPS_PROXY:-}
        ftp_proxy: ${FTP_PROXY:-}
        no_proxy: ${NO_PROXY:-}
    environment:
      HTPP_PROXY: ${HTPP_PROXY:-}
      HTTPS_PROXY: ${HTTPS_PROXY:-}
      FTP_PROXY: ${FTP_PROXY:-}
      NO_PROXY: ${NO_PROXY:-}
      http_proxy: ${HTTP_PROXY:-}
      https_proxy: ${HTTPS_PROXY:-}
      ftp_proxy: ${FTP_PROXY:-}
      no_proxy: ${NO_PROXY:-}
    user: teramatsu
    working_dir: /teramatsu/create-gguf-file-llama-cpp
    volumes:
      - ./:/teramatsu/create-gguf-file-llama-cpp
    tty: true
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: '10m'
